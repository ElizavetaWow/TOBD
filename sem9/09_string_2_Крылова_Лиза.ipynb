{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слве есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['высокопревосходительства',\n",
       " 'попреблагорассмотрительст',\n",
       " 'попреблагорассмотрительствующемуся',\n",
       " 'убегающих',\n",
       " 'уменьшившейся']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "with open('litw-win.txt') as fp:\n",
    "    for line in fp:\n",
    "        words.append(line.strip().split()[-1])\n",
    "words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = word_tokenize(text)\n",
    "for i, word in enumerate(sent):\n",
    "    if not word in words:\n",
    "        sent[i] = min(words, key=lambda k: edit_distance(word, k))\n",
    "' '.join(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = '''Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['счита', 'слов', 'из', 'файл', '`']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('russian')\n",
    "sent = word_tokenize(cond)\n",
    "res = []\n",
    "for word in sent:\n",
    "   res.append(stemmer.stem(word))\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['считать', 'слово', 'из', 'файл', '`']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "sent = word_tokenize(cond)\n",
    "res = []\n",
    "for word in sent:\n",
    "   res.append(morph.parse(word)[0].normalized.word)\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Считайте слова из файла `litw-win.txt` и запишите их в список `words`.',\n",
       " 'В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`.',\n",
       " 'Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = '''Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. '''\n",
    "sents = sent_tokenize(cond)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(sents)\n",
    "sents_cv = cv.transform(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_cv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'считайте': 32,\n",
       " 'слова': 24,\n",
       " 'из': 12,\n",
       " 'файла': 33,\n",
       " 'litw': 0,\n",
       " 'win': 2,\n",
       " 'txt': 1,\n",
       " 'запишите': 11,\n",
       " 'их': 14,\n",
       " 'список': 31,\n",
       " 'words': 3,\n",
       " 'заданном': 9,\n",
       " 'предложении': 22,\n",
       " 'исправьте': 13,\n",
       " 'все': 5,\n",
       " 'опечатки': 21,\n",
       " 'заменив': 10,\n",
       " 'опечатками': 20,\n",
       " 'на': 16,\n",
       " 'ближайшие': 4,\n",
       " 'смысле': 27,\n",
       " 'расстояния': 23,\n",
       " 'левенштейна': 15,\n",
       " 'ним': 18,\n",
       " 'списка': 29,\n",
       " 'что': 34,\n",
       " 'слове': 25,\n",
       " 'есть': 8,\n",
       " 'опечатка': 19,\n",
       " 'если': 7,\n",
       " 'данное': 6,\n",
       " 'слово': 26,\n",
       " 'не': 17,\n",
       " 'содержится': 28,\n",
       " 'списке': 30}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_descriptions.csv') as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    next(reader)\n",
    "    words_all = []\n",
    "    for row in reader:\n",
    "        words_all.extend(word_tokenize(row[1]))\n",
    "words = list(set(words_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startedstill mobile 10\n",
      "ja aromas 5\n",
      "lunchessuppers awayyyyyyyy 14\n",
      "cholent chiken 3\n",
      "viscosity dewitt 7\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    w1 = words[random.randint(0, len(words)-1)]\n",
    "    w2 = words[random.randint(0, len(words)-1)]\n",
    "    print(w1, w2, edit_distance(w1, w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(word, k):\n",
    "    ls = list(map(lambda x: [edit_distance(x, word), x], words))\n",
    "    ls.sort()\n",
    "    return [w[1] for w in ls[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mildred', 'milder', 'milled', 'miller', 'milner', 'minded', 'molded']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest(\"mildredr\", 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>perth</th>\n",
       "      <td>perth</td>\n",
       "      <td>perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dss</th>\n",
       "      <td>dss</td>\n",
       "      <td>ds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electrolytes</th>\n",
       "      <td>electrolyt</td>\n",
       "      <td>electrolyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aka</th>\n",
       "      <td>aka</td>\n",
       "      <td>aka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additinal</th>\n",
       "      <td>additin</td>\n",
       "      <td>additinal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             stemmed_word normalized_word\n",
       "word                                     \n",
       "perth               perth           perth\n",
       "dss                   dss              ds\n",
       "electrolytes   electrolyt     electrolyte\n",
       "aka                   aka             aka\n",
       "additinal         additin       additinal"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "wnlem = WordNetLemmatizer()\n",
    "df = pd.DataFrame(list(map(lambda word: [word, stemmer.stem(word), wnlem.lemmatize(word)], words)), columns=['word', 'stemmed_word', 'normalized_word']).set_index('word')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 40072),\n",
       " ('a', 34951),\n",
       " ('and', 30245),\n",
       " ('this', 26859),\n",
       " ('i', 24836),\n",
       " ('to', 23471),\n",
       " ('is', 20285),\n",
       " ('it', 19756),\n",
       " ('of', 18364),\n",
       " ('for', 15939)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(words_all)\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_filt = list(filter(lambda x: x not in stopwords.words('english'), words_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4567343213118679"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(words_all) - len(words_filt))/len(words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recipe', 14871),\n",
       " ('make', 6326),\n",
       " ('time', 5137),\n",
       " ('use', 4620),\n",
       " ('great', 4430),\n",
       " ('like', 4167),\n",
       " ('easy', 4152),\n",
       " ('one', 3872),\n",
       " ('made', 3810),\n",
       " ('good', 3791)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(words_filt)\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my way of   steamed cabbage</td>\n",
       "      <td>i remember when i was growing up watching my g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple vanilla milkshake</td>\n",
       "      <td>simple and tasty  i havent really tried this  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pancake cupcakes with maple bacon buttercream ...</td>\n",
       "      <td>the cupcakes are based on a homemade pancake b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple squares or apple coffee cake</td>\n",
       "      <td>a neighbor brought these over as a thankyou gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buttermilk pumpkin waffles</td>\n",
       "      <td>from the blog of judicial peach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        my way of   steamed cabbage   \n",
       "1                           simple vanilla milkshake   \n",
       "2  pancake cupcakes with maple bacon buttercream ...   \n",
       "3                 apple squares or apple coffee cake   \n",
       "4                         buttermilk pumpkin waffles   \n",
       "\n",
       "                           preprocessed_descriptions  \n",
       "0  i remember when i was growing up watching my g...  \n",
       "1  simple and tasty  i havent really tried this  ...  \n",
       "2  the cupcakes are based on a homemade pancake b...  \n",
       "3  a neighbor brought these over as a thankyou gi...  \n",
       "4                    from the blog of judicial peach  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = pd.read_csv('preprocessed_descriptions.csv')\n",
    "descs = descriptions.sample(5)\n",
    "descs.reset_index(drop=True, inplace=True)\n",
    "descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 0.08638831615212339, 0.0, 0.086388316152...\n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.24193021739697043,...\n",
       "2    [0.0, 0.0, 0.13473625547007598, 0.0, 0.0, 0.09...\n",
       "3    [0.14359060776268162, 0.0, 0.0, 0.0, 0.1158479...\n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: vect, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer()\n",
    "tv.fit(descs['preprocessed_descriptions'])\n",
    "descs['vect'] = [i for i in tv.transform(descs['preprocessed_descriptions']).toarray()]\n",
    "descs['vect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>my way of   steamed cabbage</th>\n",
       "      <th>simple vanilla milkshake</th>\n",
       "      <th>pancake cupcakes with maple bacon buttercream frosting</th>\n",
       "      <th>apple squares or apple coffee cake</th>\n",
       "      <th>buttermilk pumpkin waffles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>my way of   steamed cabbage</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884581</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.956575</td>\n",
       "      <td>0.868206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple vanilla milkshake</th>\n",
       "      <td>0.884581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pancake cupcakes with maple bacon buttercream frosting</th>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.872714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982645</td>\n",
       "      <td>0.889851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple squares or apple coffee cake</th>\n",
       "      <td>0.956575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buttermilk pumpkin waffles</th>\n",
       "      <td>0.868206</td>\n",
       "      <td>0.868348</td>\n",
       "      <td>0.889851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                                my way of   steamed cabbage  \\\n",
       "name                                                                              \n",
       "my way of   steamed cabbage                                            0.000000   \n",
       "simple vanilla milkshake                                               0.884581   \n",
       "pancake cupcakes with maple bacon buttercream f...                     0.736059   \n",
       "apple squares or apple coffee cake                                     0.956575   \n",
       "buttermilk pumpkin waffles                                             0.868206   \n",
       "\n",
       "name                                                simple vanilla milkshake  \\\n",
       "name                                                                           \n",
       "my way of   steamed cabbage                                         0.884581   \n",
       "simple vanilla milkshake                                            0.000000   \n",
       "pancake cupcakes with maple bacon buttercream f...                  0.872714   \n",
       "apple squares or apple coffee cake                                  1.000000   \n",
       "buttermilk pumpkin waffles                                          0.868348   \n",
       "\n",
       "name                                                pancake cupcakes with maple bacon buttercream frosting  \\\n",
       "name                                                                                                         \n",
       "my way of   steamed cabbage                                                                  0.736059        \n",
       "simple vanilla milkshake                                                                     0.872714        \n",
       "pancake cupcakes with maple bacon buttercream f...                                           0.000000        \n",
       "apple squares or apple coffee cake                                                           0.982645        \n",
       "buttermilk pumpkin waffles                                                                   0.889851        \n",
       "\n",
       "name                                                apple squares or apple coffee cake  \\\n",
       "name                                                                                     \n",
       "my way of   steamed cabbage                                                   0.956575   \n",
       "simple vanilla milkshake                                                      1.000000   \n",
       "pancake cupcakes with maple bacon buttercream f...                            0.982645   \n",
       "apple squares or apple coffee cake                                            0.000000   \n",
       "buttermilk pumpkin waffles                                                    1.000000   \n",
       "\n",
       "name                                                buttermilk pumpkin waffles  \n",
       "name                                                                            \n",
       "my way of   steamed cabbage                                           0.868206  \n",
       "simple vanilla milkshake                                              0.868348  \n",
       "pancake cupcakes with maple bacon buttercream f...                    0.889851  \n",
       "apple squares or apple coffee cake                                    1.000000  \n",
       "buttermilk pumpkin waffles                                            0.000000  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist = pd.DataFrame([[cosine(descs['vect'][i], descs['vect'][j]) for j in range(len(descs))] for i in range(len(descs))], columns=descs['name'], index=descs['name'])\n",
    "cos_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "my way of   steamed cabbage                               0.0\n",
       "simple vanilla milkshake                                  0.0\n",
       "pancake cupcakes with maple bacon buttercream frosting    0.0\n",
       "apple squares or apple coffee cake                        0.0\n",
       "buttermilk pumpkin waffles                                0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее похожие рецепты имеют косинусное растояние близкое к 0, на диагонали в дф стоят нули, так как это один и тот же рецепт. Остальные рецепты довольно разные, так как растояние очень близко к 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
